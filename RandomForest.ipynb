{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qSEmW2ojWOOI",
        "outputId": "3c925a59-dbab-4112-99e9-2ad0f9147a40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('Iris.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ1KDTcHWSj5",
        "outputId": "3a2d64bd-0d12-4bac-d758-0307c119aeb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "data['Species']= label_encoder.fit_transform(data['Species'])\n",
        "\n",
        "data['Species'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SkzTbrp02IoT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Calculate Entropy\n",
        "def entropy(y: np.ndarray) -> np.float64:\n",
        "    \"\"\"\n",
        "    Calculate the entropy of a given set of labels.\n",
        "\n",
        "    Parameters:\n",
        "    y (array-like): Labels array.\n",
        "\n",
        "    Returns:\n",
        "    float: Entropy value.\n",
        "    \"\"\"\n",
        "    # Begin your code here\n",
        "    hist = np.bincount(y)\n",
        "    ps = hist/len(y)\n",
        "    e = - np.sum([p * np.log2(p) for p in ps if p > 0])\n",
        "    # End your code here\n",
        "    return e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VwXFerCI2O3j"
      },
      "outputs": [],
      "source": [
        "# Create Node\n",
        "class Node:\n",
        "\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        \"\"\"\n",
        "        Initialize a Node object for decision tree.\n",
        "\n",
        "        Parameters:\n",
        "        feature (int or str): Index or name of the feature to split on.\n",
        "        threshold (float): Threshold value for splitting.\n",
        "        left (Node): Left child node.\n",
        "        right (Node): Right child node.\n",
        "        value (int): Value at leaf node (class label).\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        \"\"\"\n",
        "        Check if the node is a leaf node.\n",
        "\n",
        "        Returns:\n",
        "        bool: True if the node is a leaf node, False otherwise.\n",
        "        \"\"\"\n",
        "        return self.value is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FUQZpqtm2TRn"
      },
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "class DecissionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None, max_features='auto'):\n",
        "        \"\"\"\n",
        "        Initialize a DecisionTree object.\n",
        "\n",
        "        Parameters:\n",
        "        min_samples_split (int): Minimum number of samples required to split a node.\n",
        "        max_depth (int): Maximum depth of the tree.\n",
        "        n_feats (int): Number of features to consider when looking for the best split.\n",
        "        max_features (str or int or float): Strategy to select the number of features.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.n_feats = n_feats\n",
        "        self.root = None\n",
        "        self.max_features = max_features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the decision tree to the training data.\n",
        "\n",
        "        Parameters:\n",
        "        X (array-like): Training data features.\n",
        "        y (array-like): Target values.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
        "        self.cols = list(X.columns)\n",
        "        self.root = self.grow_tree(X, y)\n",
        "\n",
        "    def grow_tree(self, X, y, depth=0):\n",
        "        \"\"\"\n",
        "        Recursively grow the decision tree.\n",
        "\n",
        "        Parameters:\n",
        "        X (array-like): Training data features.\n",
        "        y (array-like): Target values.\n",
        "        depth (int): Current depth of the tree.\n",
        "\n",
        "        Returns:\n",
        "        Node: Root node of the decision tree.\n",
        "        \"\"\"\n",
        "        df = X.copy()\n",
        "        df['target'] = y\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # stopping criteria\n",
        "        if (depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
        "            leaf_value = self.most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # array of random columns in Dataset\n",
        "\n",
        "        data = self.feature_sampling(X, self.max_features)\n",
        "\n",
        "        feats_idxs = list(data.columns)\n",
        "\n",
        "        best_feat, best_thresh = self.best_criteria(X, y.tolist(), feats_idxs)\n",
        "\n",
        "        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n",
        "\n",
        "        left = self.grow_tree(left_df.drop('target', axis=1), left_df['target'].values, depth+1)\n",
        "        right = self.grow_tree(right_df.drop('target', axis=1), right_df['target'].values, depth+1)\n",
        "\n",
        "        return Node(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def best_criteria(self, X, y, feats_idxs):\n",
        "        \"\"\"\n",
        "        Find the best splitting criterion for the decision tree.\n",
        "\n",
        "        Parameters:\n",
        "        X (array-like): Training data features.\n",
        "        y (array-like): Target values.\n",
        "        feats_idxs (list): List of feature indices.\n",
        "\n",
        "        Returns:\n",
        "        tuple: Best feature index and threshold value.\n",
        "        \"\"\"\n",
        "        best_gain = -1\n",
        "        split_idx, split_tresh = None, None\n",
        "\n",
        "        X = X.to_numpy()\n",
        "\n",
        "        for feats_idx in feats_idxs:\n",
        "\n",
        "            index = int(self.cols.index(feats_idx))\n",
        "\n",
        "            df = pd.DataFrame(X[:, index], columns=['X_col'])\n",
        "            df['y'] = y\n",
        "            df = df.sort_values(by=['X_col'], ascending=True)\n",
        "\n",
        "            X_col_2 = df.X_col\n",
        "            y_2 = df.y\n",
        "\n",
        "            X_col_2 = X_col_2.to_numpy()\n",
        "            y_2 = y_2.to_numpy()\n",
        "\n",
        "            for val in X_col_2:\n",
        "                gain = self.information_gain(y_2, X_col_2, val)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    split_idx = feats_idx\n",
        "                    split_tresh = val\n",
        "\n",
        "        return split_idx, split_tresh\n",
        "\n",
        "    def information_gain(self, y, X_col, thresh):\n",
        "        \"\"\"\n",
        "        Calculate the information gain for a split.\n",
        "\n",
        "        Parameters:\n",
        "        y (array-like): Target values.\n",
        "        X_col (array-like): Feature values.\n",
        "        thresh (float): Threshold value for splitting.\n",
        "\n",
        "        Returns:\n",
        "        float: Information gain.\n",
        "        \"\"\"\n",
        "        parent_entropy = entropy(y)\n",
        "\n",
        "        left, right = self.split(X_col, thresh)\n",
        "\n",
        "        if len(left) == 0 or len(right) == 0:\n",
        "            return 0\n",
        "\n",
        "        n = len(y)\n",
        "        n_l, n_r = len(left), len(right)\n",
        "        e_l, e_r = entropy(y[left]), entropy(y[right])\n",
        "\n",
        "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
        "\n",
        "        ig = parent_entropy - child_entropy\n",
        "        return ig\n",
        "\n",
        "    def split(self, X_col, split_tresh):\n",
        "        \"\"\"\n",
        "        Split the data based on a threshold.\n",
        "\n",
        "        Parameters:\n",
        "        X_col (array-like): Feature values.\n",
        "        split_tresh (float): Threshold value for splitting.\n",
        "\n",
        "        Returns:\n",
        "        tuple: Indices of samples in left and right splits.\n",
        "        \"\"\"\n",
        "        left_idxs = np.argwhere(X_col <= split_tresh).flatten()\n",
        "        right_idxs = np.argwhere(X_col > split_tresh).flatten()\n",
        "\n",
        "        return left_idxs, right_idxs\n",
        "\n",
        "    def most_common_label(self, y):\n",
        "        \"\"\"\n",
        "        Find the most common label in a set of labels.\n",
        "\n",
        "        Parameters:\n",
        "        y (array-like): Target values.\n",
        "\n",
        "        Returns:\n",
        "        int: Most common label.\n",
        "        \"\"\"\n",
        "        counter = Counter(y)\n",
        "        most_common = counter.most_common(1)[0][0]\n",
        "        return most_common\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted decision tree.\n",
        "\n",
        "        Parameters:\n",
        "        X (array-like): Test data features.\n",
        "\n",
        "        Returns:\n",
        "        array-like: Predicted target values.\n",
        "        \"\"\"\n",
        "        X = X.to_numpy().tolist()\n",
        "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def traverse_tree(self, x, node):\n",
        "        \"\"\"\n",
        "        Traverse the decision tree to make a prediction for a single sample.\n",
        "\n",
        "        Parameters:\n",
        "        x (array-like): Feature values for a single sample.\n",
        "        node (Node): Current node in the decision tree.\n",
        "\n",
        "        Returns:\n",
        "        int: Predicted target value.\n",
        "        \"\"\"\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "\n",
        "        index = int(self.cols.index(node.feature))\n",
        "\n",
        "        if x[index] <= node.threshold:\n",
        "            return self.traverse_tree(x, node.left)\n",
        "\n",
        "        return self.traverse_tree(x, node.right)\n",
        "\n",
        "    def feature_sampling(self, data, val):\n",
        "        \"\"\"\n",
        "        Perform feature sampling based on the specified strategy.\n",
        "\n",
        "        Parameters:\n",
        "        data (DataFrame): Input data.\n",
        "        val (int or float or str): Sampling strategy or number of features to sample.\n",
        "\n",
        "        Returns:\n",
        "        DataFrame: Sampled data.\n",
        "        \"\"\"\n",
        "        if type(val) == int:\n",
        "            col = random.sample(data.columns.tolist()[:], val)\n",
        "            new_df = data[col]\n",
        "            return new_df\n",
        "        elif type(val) == float:\n",
        "            col = random.sample(data.columns.tolist()[:], int(val * data.shape[1]))\n",
        "            new_df = data[col]\n",
        "            return new_df\n",
        "        elif val == 'auto' or val == 'sqrt':\n",
        "            col = random.sample(data.columns.tolist()[:], int(math.sqrt(data.shape[1])))\n",
        "            new_df = data[col]\n",
        "            return new_df\n",
        "        elif val == 'log2':\n",
        "            col = random.sample(data.columns.tolist()[:], int(math.log2(data.shape[1])))\n",
        "            new_df = data[col]\n",
        "            return new_df\n",
        "        else:\n",
        "            return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "puPekdSC2gTZ"
      },
      "outputs": [],
      "source": [
        "class randomforestclassifier:\n",
        "    def __init__(self, n_estimators=100, criterion='entropy', max_depth=None, min_samples_split=2, bootstrap=True, max_samples=None,\n",
        "                 max_features='auto', oob_score=False):\n",
        "        \"\"\"\n",
        "        Initialize a RandomForestClassifier object.\n",
        "\n",
        "        Parameters:\n",
        "        n_estimators (int): Number of trees in the forest.\n",
        "        criterion (str): Splitting criterion for decision trees.\n",
        "        max_depth (int): Maximum depth of the trees.\n",
        "        min_samples_split (int): Minimum number of samples required to split a node.\n",
        "        bootstrap (bool): Whether bootstrap samples are used when building trees.\n",
        "        max_samples (int or float): Number of samples to draw from X to train each base estimator.\n",
        "        max_features (str or int or float): Strategy to select the number of features.\n",
        "        oob_score (bool): Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        self.n_estimators = n_estimators\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.bootstrap = bootstrap\n",
        "        self.max_samples = max_samples\n",
        "        self.max_features = max_features\n",
        "        self.oob_score = oob_score\n",
        "\n",
        "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
        "        \"\"\"\n",
        "        Fit the random forest classifier to the training data.\n",
        "\n",
        "        Parameters:\n",
        "        X_train (array-like): Training data features.\n",
        "        y_train (array-like): Target values.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        # Begin your code here\n",
        "        dummy_data = X_train.copy()\n",
        "        dummy_data['target'] = y_train\n",
        "        \n",
        "        self.tree_list = []\n",
        "        \n",
        "        for i in range(self.n_estimators):\n",
        "            \n",
        "            if self.bootstrap == True:\n",
        "                df = self.row_sampling(dummy_data, self.max_samples)\n",
        "            else:\n",
        "                df = dummy_data.copy()\n",
        "            \n",
        "            tree = DecissionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split, max_features=self.max_features)\n",
        "            \n",
        "            tree.fit(df.drop('target', axis=1), df.target)\n",
        "\n",
        "            self.tree_list.append(tree)\n",
        "        # End your code here\n",
        "        return None\n",
        "\n",
        "\n",
        "    def predict(self, X_test: pd.DataFrame) -> list:\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted random forest classifier.\n",
        "\n",
        "        Parameters:\n",
        "        X_test (array-like): Test data features.\n",
        "\n",
        "        Returns:\n",
        "        array-like: Predicted target values.\n",
        "        \"\"\"\n",
        "        # Begin your code here\n",
        "        y_preds = np.empty((X_test.shape[0], len(self.tree_list)))\n",
        "        # Let each tree make a prediction on the data\n",
        "        for i, tree in enumerate(self.tree_list):\n",
        "            # Indices of the features that the tree has trained on\n",
        "            # idx = tree.feature_indices\n",
        "            # Make a prediction based on those features\n",
        "            prediction = tree.predict(X_test)\n",
        "            y_preds[:, i] = prediction\n",
        "        \n",
        "        y_pred = []\n",
        "        # For each sample\n",
        "        for sample_predictions in y_preds:\n",
        "            # Select the most common class prediction\n",
        "            y_pred.append(np.bincount(sample_predictions.astype('int')).argmax())\n",
        "        \n",
        "        print(type(X_test))\n",
        "        print(type(y_pred))\n",
        "        # End your code here\n",
        "        return y_pred\n",
        "\n",
        "    def score(self, y_true=None, y_pred=None):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy score of the classifier.\n",
        "\n",
        "        Parameters:\n",
        "        y_true (array-like): True target values.\n",
        "        y_pred (array-like): Predicted target values.\n",
        "\n",
        "        Returns:\n",
        "        float: Accuracy score.\n",
        "        \"\"\"\n",
        "        acc = np.sum(y_true == y_pred)/len(y_true)\n",
        "        return acc\n",
        "\n",
        "    def row_sampling(self, data, val):\n",
        "        \"\"\"\n",
        "        Perform row sampling based on the specified strategy.\n",
        "\n",
        "        Parameters:\n",
        "        data (DataFrame): Input data.\n",
        "        val (int or float): Sampling strategy or number of samples to sample.\n",
        "\n",
        "        Returns:\n",
        "        DataFrame: Sampled data.\n",
        "        \"\"\"\n",
        "        if type(val) == float:\n",
        "            return data.sample(int(val * data.shape[0]), replace=True)\n",
        "        if type(val) == int:\n",
        "            return data.sample(val, replace=True)\n",
        "        if val == None:\n",
        "            return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NlzPeOnX2oRP"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    x = data.drop('Species', axis=1)\n",
        "    y = data.Species\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "    re = randomforestclassifier(n_estimators=10, max_depth=5, min_samples_split=5, max_samples=50, max_features=3)\n",
        "\n",
        "    re.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HdGUOW6K2r7v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "y_pred = re.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "clOjWtSU2uZ2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n"
          ]
        }
      ],
      "source": [
        "sc = re.score(y_test, y_pred)\n",
        "print('Accuracy :', sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xL6-UDiq2w4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 0.9866666666666667\n"
          ]
        }
      ],
      "source": [
        "# Part 2:\n",
        "# Importing necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Creating a random forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Training the classifier on the training set\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the train and test sets\n",
        "y_train_pred = rf_classifier.predict(X_train)\n",
        "y_test_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculating accuracy for train and test sets\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
